{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "import pickle\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/azureuser/MLOps_zoomcamp/mlruns/1', creation_time=1691845828281, experiment_id='1', last_update_time=1691845828281, lifecycle_stage='active', name='housing-price', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment('housing-price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/Housing_dataset_train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_zone = {\n",
    "    \"Abia\": \"South-East\",\n",
    "    \"Adamawa\": \"North-East\",\n",
    "    \"Akwa Ibom\": \"South-South\",\n",
    "    \"Anambra\": \"South-East\",\n",
    "    \"Bauchi\": \"North-East\",\n",
    "    \"Bayelsa\": \"South-South\",\n",
    "    \"Benue\": \"North-Central\",\n",
    "    \"Borno\": \"North-East\",\n",
    "    \"Cross River\": \"South-South\",\n",
    "    \"Delta\": \"South-South\",\n",
    "    \"Ebonyi\": \"South-East\",\n",
    "    \"Edo\": \"South-South\",\n",
    "    \"Ekiti\": \"South-West\",\n",
    "    \"Enugu\": \"South-East\",\n",
    "    \"Gombe\": \"North-East\",\n",
    "    \"Imo\": \"South-East\",\n",
    "    \"Jigawa\": \"North-West\",\n",
    "    \"Kaduna\": \"North-West\",\n",
    "    \"Kano\": \"North-West\",\n",
    "    \"Katsina\": \"North-West\",\n",
    "    \"Kebbi\": \"North-West\",\n",
    "    \"Kogi\": \"North-Central\",\n",
    "    \"Kwara\": \"North-Central\",\n",
    "    \"Lagos\": \"South-West\",\n",
    "    \"Nasarawa\": \"North-Central\",\n",
    "    \"Niger\": \"North-Central\",\n",
    "    \"Ogun\": \"South-West\",\n",
    "    \"Ondo\": \"South-West\",\n",
    "    \"Osun\": \"South-West\",\n",
    "    \"Oyo\": \"South-West\",\n",
    "    \"Plateau\": \"North-Central\",\n",
    "    \"Rivers\": \"South-South\",\n",
    "    \"Sokoto\": \"North-West\",\n",
    "    \"Taraba\": \"North-East\",\n",
    "    \"Yobe\": \"North-East\",\n",
    "    \"Zamfara\": \"North-West\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_type_ranks = {\n",
    "    'Cottage': 1,\n",
    "    'Bungalow': 2,\n",
    "    'Townhouse': 3,\n",
    "    'Terrace duplex': 4,\n",
    "    'Detached duplex': 5,\n",
    "    'Semi-detached duplex': 6,\n",
    "    'Flat': 7,\n",
    "    'Penthouse': 8,\n",
    "    'Apartment': 9,\n",
    "    'Mansion': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "\n",
    "    print(data.columns.tolist())\n",
    "    \n",
    "    data['zone'] = data['loc'].map(state_to_zone)\n",
    "    data['title'] = data['title'].map(house_type_ranks)\n",
    "\n",
    "    category_frequencies = data['loc'].value_counts(normalize=True)\n",
    "    loc_frequency_mapping = category_frequencies.to_dict()\n",
    "    data['loc'] = data['loc'].map(loc_frequency_mapping)\n",
    "\n",
    "    data['rooms'] = data['bathroom'] + data['bedroom']\n",
    "    data['bathroom_ratio'] = data['bathroom']/(data['bathroom'] + data['bedroom'])\n",
    "\n",
    "    data['zone'] = data['zone'].astype('category').cat.codes\n",
    "\n",
    "    print(\"_____________________________________________________________________________\")\n",
    "    print(data.head())\n",
    "\n",
    "    X = data.drop(columns=['price'], axis=0)\n",
    "    y = data.price\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'loc', 'title', 'bedroom', 'bathroom', 'parking_space', 'price']\n",
      "_____________________________________________________________________________\n",
      "      ID       loc  title  bedroom  bathroom  parking_space        price  \\\n",
      "0   3583  0.028309    6.0      2.0       2.0            1.0  1149999.565   \n",
      "1   2748  0.028227    9.0      NaN       2.0            4.0  1672416.689   \n",
      "2   9261  0.027570    NaN      7.0       5.0            NaN  3364799.814   \n",
      "3   2224  0.029786    5.0      5.0       2.0            4.0  2410306.756   \n",
      "4  10300  0.026340    4.0      NaN       5.0            6.0  2600700.898   \n",
      "\n",
      "   zone  rooms  bathroom_ratio  \n",
      "0     2    4.0        0.500000  \n",
      "1     5    NaN             NaN  \n",
      "2     5   12.0        0.416667  \n",
      "3     3    7.0        0.285714  \n",
      "4     0    NaN             NaN  \n"
     ]
    }
   ],
   "source": [
    "X_, y_ = preprocess(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.lightgbm.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 396\n",
      "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score 1425.058519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "err: 529324.2298639654\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 396\n",
      "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 9\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Start training from score 1423.011279\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "err: 571620.4886453262\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    params = {\n",
    "        'max_depth': 10,\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': 0.002712819361612371,\n",
    "        'colsample_bytree': 0.9484547548287134,\n",
    "        'subsample': 0.8490126211976283\n",
    "        }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    fold_pred = []\n",
    "    splits = 2\n",
    "    fold = KFold(n_splits=splits)\n",
    "\n",
    "    for data_index, test_index in fold.split(X_, y_):\n",
    "        X_data, X_test = X_.iloc[data_index], X_.iloc[test_index]\n",
    "        y_data, y_test = np.sqrt(y_.iloc[data_index]), y_.iloc[test_index]\n",
    "\n",
    "        model = LGBMRegressor(**params, objective='rmse')\n",
    "        model.fit(X_data, y_data, eval_set=[(X_data, y_data), (X_test, y_test)])\n",
    "        model_preds = model.predict(X_test)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, np.square(model_preds), squared=False)\n",
    "        print(f'err: {rmse}')\n",
    "        fold_pred.append(rmse)\n",
    "\n",
    "    RMSE = np.mean(fold_pred)\n",
    "\n",
    "    mlflow.log_param(\"splits\", splits)\n",
    "    mlflow.log_metric(\"rmse\", RMSE)\n",
    "    \n",
    "    with open('models/lgb.bin', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"models/lgb.bin\", artifact_path=\"models_pickle\")\n",
    "    mlflow.lightgbm.log_model(model, artifact_path=\"models_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: 466743.0169847345\n",
      "err: 524069.56855255977\n",
      "err: 638941.7498937332\n",
      "err: 470119.679511906\n",
      "err: 476696.0579938225\n",
      "err: 588413.1371192657\n",
      "err: 552106.7342063364\n",
      "err: 494535.4359102119\n",
      "err: 513112.49038561864\n",
      "err: 633301.7921100028\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    params = {\n",
    "        'max_depth': 10,\n",
    "        'n_estimators': 2000,\n",
    "        'subsample': 0.84,\n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators' : 2000\n",
    "        }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    fold_pred_1 = []\n",
    "    splits = 10\n",
    "    fold = KFold(n_splits=splits)\n",
    "\n",
    "    for data_index, test_index in fold.split(X_, y_):\n",
    "        X_data, X_test = X_.iloc[data_index], X_.iloc[test_index]\n",
    "        y_data, y_test = np.sqrt(y_.iloc[data_index]), y_.iloc[test_index]\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X_data, y_data, eval_set=[(X_data, y_data), (X_test, y_test)], verbose=0)\n",
    "        model_preds = model.predict(X_test)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, np.square(model_preds), squared=False)\n",
    "        print(f'err: {rmse}')\n",
    "        fold_pred_1.append(rmse)\n",
    "\n",
    "    RMSE = np.mean(fold_pred_1)\n",
    "\n",
    "    mlflow.log_param(\"splits\", splits)\n",
    "    mlflow.log_metric(\"rmse\", RMSE)\n",
    "    \n",
    "    with open('models/cat.bin', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"models/cat.bin\", artifact_path=\"models_pickle\")\n",
    "    mlflow.catboost.log_model(model, artifact_path=\"models_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: 491728.36126421625\n",
      "err: 547610.9804050468\n",
      "err: 653658.618074101\n",
      "err: 496614.536246212\n",
      "err: 482955.2736791648\n",
      "err: 615508.374548473\n",
      "err: 557145.6781747503\n",
      "err: 516872.42737316753\n",
      "err: 581392.2704359363\n",
      "err: 649455.7368549954\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "\n",
    "    params = {\n",
    "        'max_depth': 10,\n",
    "        'n_estimators': 2000,\n",
    "        'subsample': 0.84,\n",
    "        'learning_rate': 0.01,\n",
    "        'n_estimators' : 2000\n",
    "        }\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    fold_pred_1 = []\n",
    "    splits = 10\n",
    "    fold = KFold(n_splits=splits)\n",
    "\n",
    "    for data_index, test_index in fold.split(X_, y_):\n",
    "        X_data, X_test = X_.iloc[data_index], X_.iloc[test_index]\n",
    "        y_data, y_test = np.sqrt(y_.iloc[data_index]), y_.iloc[test_index]\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_data, y_data, eval_set=[(X_data, y_data), (X_test, y_test)], verbose=0)\n",
    "        model_preds = model.predict(X_test)\n",
    "\n",
    "        rmse = mean_squared_error(y_test, np.square(model_preds), squared=False)\n",
    "        print(f'err: {rmse}')\n",
    "        fold_pred_1.append(rmse)\n",
    "\n",
    "    RMSE = np.mean(fold_pred_1)\n",
    "\n",
    "    mlflow.log_param(\"splits\", splits)\n",
    "    mlflow.log_metric(\"rmse\", RMSE)\n",
    "    \n",
    "    with open('models/xgb.bin', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    mlflow.log_artifact(local_path=\"models/xgb.bin\", artifact_path=\"models_pickle\")\n",
    "    mlflow.xgboost.log_model(model, artifact_path=\"models_mlflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MlflowClient' object has no attribute 'list_experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client\u001b[39m.\u001b[39;49mlist_experiments()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MlflowClient' object has no attribute 'list_experiments'"
     ]
    }
   ],
   "source": [
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "\n",
    "#     max_depth = trial.suggest_int('rf_max_depth', 2, 32)\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 100, 4000)\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0, 1)\n",
    "#     subsample = trial.suggest_float('subsample', 0, 1)\n",
    "\n",
    "#     params = {\n",
    "#         'max_depth':max_depth,\n",
    "#         'colsample_bytree': colsample_bytree,\n",
    "#         'learning_rate': learning_rate,\n",
    "#         'n_estimators': n_estimators,\n",
    "#         'subsample': subsample,\n",
    "#     }\n",
    "\n",
    "#     X_data, X_val, y_data, y_val = data_test_split(X, y, random_state=RANDOM_STATE)\n",
    "\n",
    "#     LGB = CatBoostRegressor(**params)\n",
    "#     LGB.fit(X_data, y_data)\n",
    "#     y_pred = LGB.predict(X_val)\n",
    "\n",
    "#     error = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "#     return error  # An objective value linked with the Trial object.\n",
    "\n",
    "#  # Invoke optimization of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    max_depth = trial.suggest_int('rf_max_depth', 2, 16)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 4000)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0, 1)\n",
    "    subsample = trial.suggest_float('subsample', 0, 1)\n",
    "\n",
    "    params = {\n",
    "        'max_depth':max_depth,\n",
    "#         'colsample_bytree': colsample_bytree,\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators': n_estimators,\n",
    "        'subsample': subsample,\n",
    "    }\n",
    "\n",
    "    X_data, X_val, y_data, y_val = data_test_split(X, y, random_state=RANDOM_STATE)\n",
    "\n",
    "    CAT = CatBoostRegressor(**params)\n",
    "    CAT.fit(X_data, y_data, verbose=0)\n",
    "    y_pred = CAT.predict(X_val)\n",
    "\n",
    "    error = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    return error  # An objective value linked with the Trial object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-06 14:25:46,580] A new study created in memory with name: no-name-15fb2ab2-531f-4dff-b48b-b1376f15677d\n",
      "[I 2023-08-06 14:25:53,716] Trial 0 finished with value: 576129.2543902358 and parameters: {'rf_max_depth': 11, 'n_estimators': 529, 'learning_rate': 0.06455367174443834, 'subsample': 0.43625841484720584}. Best is trial 0 with value: 576129.2543902358.\n",
      "/home/gbotemi/.local/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "[I 2023-08-06 14:26:03,780] Trial 1 finished with value: 671184.3102130804 and parameters: {'rf_max_depth': 7, 'n_estimators': 3050, 'learning_rate': 0.000635824373713653, 'subsample': 0.5551330404486285}. Best is trial 0 with value: 576129.2543902358.\n",
      "/home/gbotemi/.local/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "[I 2023-08-06 14:26:18,778] Trial 2 finished with value: 562026.9602222078 and parameters: {'rf_max_depth': 8, 'n_estimators': 3403, 'learning_rate': 0.00799484164823344, 'subsample': 0.796443790960059}. Best is trial 2 with value: 562026.9602222078.\n",
      "/home/gbotemi/.local/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "[I 2023-08-06 14:26:23,031] Trial 3 finished with value: 1070936.4798938944 and parameters: {'rf_max_depth': 6, 'n_estimators': 2455, 'learning_rate': 2.3789497277117303e-05, 'subsample': 0.13411574089767897}. Best is trial 2 with value: 562026.9602222078.\n",
      "/home/gbotemi/.local/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "[I 2023-08-06 14:26:46,527] Trial 4 finished with value: 1063340.5916521929 and parameters: {'rf_max_depth': 12, 'n_estimators': 1124, 'learning_rate': 6.778579161419899e-05, 'subsample': 0.6998049090034681}. Best is trial 2 with value: 562026.9602222078.\n",
      "/home/gbotemi/.local/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "[I 2023-08-06 14:26:51,506] Trial 5 finished with value: 1054122.3571465665 and parameters: {'rf_max_depth': 8, 'n_estimators': 1720, 'learning_rate': 5.26413595074852e-05, 'subsample': 0.2564108042031683}. Best is trial 2 with value: 562026.9602222078.\n",
      "/home/gbotemi/.local/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "[I 2023-08-06 14:29:33,082] Trial 6 finished with value: 997450.2524238636 and parameters: {'rf_max_depth': 16, 'n_estimators': 501, 'learning_rate': 0.00046620704767768125, 'subsample': 0.9311336503844428}. Best is trial 2 with value: 562026.9602222078.\n",
      "/home/gbotemi/.local/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "[I 2023-08-06 14:29:42,185] Trial 7 finished with value: 1064668.8841885817 and parameters: {'rf_max_depth': 11, 'n_estimators': 739, 'learning_rate': 9.818056473822069e-05, 'subsample': 0.45665563591794267}. Best is trial 2 with value: 562026.9602222078.\n",
      "/home/gbotemi/.local/lib/python3.10/site-packages/catboost/core.py:1411: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')  # Create a new study.\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=95, state=TrialState.COMPLETE, values=[551678.5994224877], datetime_start=datetime.datetime(2023, 8, 6, 14, 17, 1, 888573), datetime_complete=datetime.datetime(2023, 8, 6, 14, 17, 7, 916277), params={'rf_max_depth': 26, 'n_estimators': 3679, 'learning_rate': 0.002712819361612371, 'colsample_bytree': 0.9484547548287134, 'subsample': 0.8490126211976283}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'rf_max_depth': IntDistribution(high=32, log=False, low=2, step=1), 'n_estimators': IntDistribution(high=4000, log=False, low=100, step=1), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.0, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.0, step=None)}, trial_id=95, value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "551678.5994224877"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf_max_depth': 26,\n",
       " 'n_estimators': 3679,\n",
       " 'learning_rate': 0.002712819361612371,\n",
       " 'colsample_bytree': 0.9484547548287134,\n",
       " 'subsample': 0.8490126211976283}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
